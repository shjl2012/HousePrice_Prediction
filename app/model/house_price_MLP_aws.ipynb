{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boto3 呼叫 aws bucket\n",
    "\n",
    "參考資料：\n",
    "\n",
    "https://dev.to/gbhorwood/managing-your-aws-resources-with-python-and-boto3-1ceb\n",
    "\n",
    "https://dev.to/aws-builders/how-to-list-contents-of-s3-bucket-using-boto3-python-47mm\n",
    "\n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/guide/session.html\n",
    "\n",
    "https://www.learnaws.org/2022/09/27/pandas-read-s3/\n",
    "\n",
    "https://aws-sdk-pandas.readthedocs.io/en/stable/tutorials/002%20-%20Sessions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "# configuration\n",
    "\n",
    "# --> NEW\n",
    "# the name of the aws profile\n",
    "aws_profile = \"house-good-job_john\"\n",
    "\n",
    "# --> NEW\n",
    "# aws credentials read in from ~/.aws/credentials\n",
    "aws_access_key_id = None\n",
    "aws_secret_access_key = None\n",
    "aws_region = \"ap-northeast-1\"\n",
    "\n",
    "\n",
    "# --> NEW\n",
    "def get_aws_credentials():\n",
    "    \"\"\"\n",
    "    Gets the aws credentials from ~/.aws/credentials\n",
    "    for the aws profile name\n",
    "    \"\"\"\n",
    "    import configparser\n",
    "    import os\n",
    "\n",
    "    # the aws profile we configured\n",
    "    global aws_profile\n",
    "\n",
    "    # the global variables where we store the aws credentials\n",
    "    global aws_access_key_id\n",
    "    global aws_secret_access_key\n",
    "\n",
    "    # parse the aws credentials file\n",
    "    path = os.environ['HOME'] + '/.aws/credentials'\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(path)\n",
    "\n",
    "    # read in the aws_access_key_id and the aws_secret_access_key\n",
    "    # if the profile does not exist, error and exit\n",
    "    if aws_profile in config.sections():\n",
    "        aws_access_key_id = config[aws_profile]['aws_access_key_id']\n",
    "        aws_secret_access_key = config[aws_profile]['aws_secret_access_key']\n",
    "    else:\n",
    "        print(\"Cannot find profile '{}' in {}\".format(aws_profile, path), True)\n",
    "        sys.exit()\n",
    "\n",
    "    # if we don't have both the access and secret key, error and exit\n",
    "    if aws_access_key_id is None or aws_secret_access_key is None:\n",
    "        print(\"AWS config values not set in '{}' in {}\".format(aws_profile, path), True)\n",
    "        sys.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_crentials confirmation\n",
    "\n",
    "# get_aws_credentials()\n",
    "# print(aws_profile)\n",
    "# print(aws_access_key_id)\n",
    "# print(aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_data/\n",
      "clean_data/KEL_model_features_clean.csv\n",
      "clean_data/NTPC_model_features_clean.csv\n",
      "clean_data/TPE_model_features_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "aws_profile = \"house-good-job_john\"\n",
    "aws_access_key_id = None\n",
    "aws_secret_access_key = None\n",
    "\n",
    "session = boto3.Session(profile_name=aws_profile)\n",
    "s3_client = session.client('s3')\n",
    "\n",
    "objects = s3_client.list_objects_v2(Bucket='house-good-job')\n",
    "\n",
    "for obj in objects['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m s3_client1 \u001b[39m=\u001b[39m session1\u001b[39m.\u001b[39mclient(\u001b[39m'\u001b[39m\u001b[39ms3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m objects1 \u001b[39m=\u001b[39m s3_client1\u001b[39m.\u001b[39mlist_objects_v2(Bucket\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstock-tw\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m objects1[\u001b[39m'\u001b[39;49m\u001b[39mContents\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[0;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(obj[\u001b[39m'\u001b[39m\u001b[39mKey\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Contents'"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "aws_profile = \"stock-tw_john\"\n",
    "aws_access_key_id = None\n",
    "aws_secret_access_key = None\n",
    "\n",
    "session1 = boto3.Session(profile_name=aws_profile)\n",
    "s3_client1 = session1.client('s3')\n",
    "\n",
    "objects1 = s3_client1.list_objects_v2(Bucket='stock-tw')\n",
    "\n",
    "for obj in objects1['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: 找不到指定的程序。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mwr\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mboto3\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mHousePriceModel_aws\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\John1\\anaconda3\\lib\\site-packages\\awswrangler\\__init__.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"Initial Module.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39mSource repository: https://github.com/aws/aws-sdk-pandas\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mDocumentation: https://aws-sdk-pandas.readthedocs.io/\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_logging\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     athena,\n\u001b[0;32m     12\u001b[0m     catalog,\n\u001b[0;32m     13\u001b[0m     chime,\n\u001b[0;32m     14\u001b[0m     cloudwatch,\n\u001b[0;32m     15\u001b[0m     data_api,\n\u001b[0;32m     16\u001b[0m     data_quality,\n\u001b[0;32m     17\u001b[0m     dynamodb,\n\u001b[0;32m     18\u001b[0m     emr,\n\u001b[0;32m     19\u001b[0m     emr_serverless,\n\u001b[0;32m     20\u001b[0m     exceptions,\n\u001b[0;32m     21\u001b[0m     lakeformation,\n\u001b[0;32m     22\u001b[0m     mysql,\n\u001b[0;32m     23\u001b[0m     neptune,\n\u001b[0;32m     24\u001b[0m     opensearch,\n\u001b[0;32m     25\u001b[0m     oracle,\n\u001b[0;32m     26\u001b[0m     postgresql,\n\u001b[0;32m     27\u001b[0m     quicksight,\n\u001b[0;32m     28\u001b[0m     redshift,\n\u001b[0;32m     29\u001b[0m     s3,\n\u001b[0;32m     30\u001b[0m     secretsmanager,\n\u001b[0;32m     31\u001b[0m     sqlserver,\n\u001b[0;32m     32\u001b[0m     sts,\n\u001b[0;32m     33\u001b[0m     timestream,\n\u001b[0;32m     34\u001b[0m     typing,\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__metadata__\u001b[39;00m \u001b[39mimport\u001b[39;00m __description__, __license__, __title__, __version__  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\John1\\anaconda3\\lib\\site-packages\\awswrangler\\athena\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"Amazon Athena Module.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mathena\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_executions\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     get_query_execution,\n\u001b[0;32m      5\u001b[0m     stop_query_execution,\n\u001b[0;32m      6\u001b[0m     start_query_execution,\n\u001b[0;32m      7\u001b[0m     wait_query,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mathena\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_spark\u001b[39;00m \u001b[39mimport\u001b[39;00m create_spark_session, run_spark_calculation\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mathena\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_read\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     get_query_results,\n\u001b[0;32m     12\u001b[0m     read_sql_query,\n\u001b[0;32m     13\u001b[0m     read_sql_table,\n\u001b[0;32m     14\u001b[0m     unload,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\John1\\anaconda3\\lib\\site-packages\\awswrangler\\athena\\_executions.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mboto3\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbotocore\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m \u001b[39mimport\u001b[39;00m _utils, exceptions, typing\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m apply_configs\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_sql_formatter\u001b[39;00m \u001b[39mimport\u001b[39;00m _process_sql_params\n",
      "File \u001b[1;32mc:\\Users\\John1\\anaconda3\\lib\\site-packages\\awswrangler\\_utils.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcredentials\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpa\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Config\n\u001b[0;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mawswrangler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\John1\\anaconda3\\lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[39m=\u001b[39m _gc\u001b[39m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[39m.\u001b[39menable()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: 找不到指定的程序。"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import joblib, os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "\n",
    "class HousePriceModel_aws:\n",
    "\n",
    "    def __init__(self, c):\n",
    "        self.cityname = c\n",
    "        self.modelpath = f'./{self.cityname}/model_mlp_aws.pkl'\n",
    "        aws_profile = \"house-good-job_john\"\n",
    "        session = boto3.Session(profile_name=aws_profile)\n",
    "        data = wr.s3.read_csv(f's3://house-good-job/clean_data/{self.cityname}_model_features_clean.csv', boto3_session=session)\n",
    "        # data=pd.read_csv(f'./{self.cityname}_model_features_clean.csv')\n",
    "        # 單熱編碼\n",
    "        data_class = pd.get_dummies(data['鄉鎮市區'])\n",
    "        data_class.columns = ['鄉鎮市區_' + str(x) for x in data_class.columns]\n",
    "        data = pd.concat([data, data_class], axis = 1)\n",
    "\n",
    "        # 刪除資料分類用欄位\n",
    "        data.insert(data.shape[1], 'y', data['單價元平方公尺'])\n",
    "        data.drop(['單價元平方公尺', 'Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.2', \n",
    "        '鄉鎮市區', 'geometry'],axis=1,inplace=True)\n",
    "\n",
    "        # 低變異過濾\n",
    "        data = data.loc[:, data.std() > 0]\n",
    "        data = data.dropna()\n",
    "        self.feature_count = data.shape[1]\n",
    "\n",
    "        # 訓練集 & 測試集\n",
    "        test_data = data.loc[data['交易年份'] >= 111]\n",
    "        test_data.to_csv(f'./{self.cityname}/test_data.csv')\n",
    "        train_data =  data.loc[data['交易年份'] < 111]\n",
    "        \n",
    "        # 資料標準化\n",
    "        self.mean = train_data.mean()\n",
    "        self.std = train_data.std()\n",
    "        self.train_data = (train_data-self.mean)/self.std\n",
    "\n",
    "        \n",
    "    def trainModel(self):\n",
    "        X_train = np.array(self.train_data.drop('y', axis='columns'))\n",
    "        y_train = np.array(self.train_data['y'])\n",
    "\n",
    "        model_mlp = MLPRegressor(random_state=14,max_iter = 400,activation='relu', hidden_layer_sizes=(int(self.feature_count*1/2),int(self.feature_count*1/4)), verbose=True)\n",
    "        model_mlp.fit(X_train, y_train)\n",
    "        mlp_score=model_mlp.score(X_train,y_train)\n",
    "\n",
    "        joblib.dump(model_mlp, f'./{self.cityname}/model_mlp_aws.pkl')\n",
    "        print(f'model score: {mlp_score}')\n",
    "\n",
    "    def testModel(self, testfile):\n",
    "        if os.path.isfile(self.modelpath):\n",
    "            test_data = pd.read_csv(f'./{self.cityname}/{testfile}.csv')\n",
    "            test_data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "            \n",
    "            test_data = (test_data - self.mean) / self.std\n",
    "            X_test = np.array(test_data.drop('y', axis='columns'))\n",
    "            y_test = np.array(test_data['y'])\n",
    "\n",
    "            \n",
    "            model_mlp = joblib.load(f'./{self.cityname}/model_mlp_aws.pkl')\n",
    "            result = model_mlp.predict(X_test)\n",
    "            fig = plt.figure(figsize=(10,5))\n",
    "            residuals = (y_test * self.std['y'] + self.mean['y'])- (result * self.std['y'] + self.mean['y'])\n",
    "            pd.DataFrame(residuals).to_csv(f'./{self.cityname}/residuals.csv')\n",
    "\n",
    "            data1 = pd.DataFrame({'origin':y_test * self.std['y'] + self.mean['y'],'predict':result* self.std['y'] + self.mean['y'],\n",
    "                                'residual':(y_test * self.std['y'] + self.mean['y']) - (result* self.std['y'] + self.mean['y'])})\n",
    "            percentage_error = np.mean(np.abs(data1['origin'] - data1['predict'])) / np.mean(data1['origin']) * 100\n",
    "            data1['residual_abs'] = data1['residual'].abs()\n",
    "            data1['y10'] = data1['origin'] / 10 - data1['residual_abs']\n",
    "            data1['y20'] = data1['origin'] / 5 - data1['residual_abs']\n",
    "            data1['y30'] = data1['origin'] / 3.333 - data1['residual_abs']\n",
    "            data1.loc[data1['y10'] >= 0, 'y10'] = 1\n",
    "            data1.loc[data1['y10'] < 0 , 'y10'] = 0\n",
    "            data1.loc[data1['y20'] >= 0, 'y20'] = 1\n",
    "            data1.loc[data1['y20'] < 0 , 'y20'] = 0\n",
    "            data1.loc[data1['y30'] >= 0, 'y30'] = 1\n",
    "            data1.loc[data1['y30'] < 0 , 'y30'] = 0\n",
    "            \n",
    "\n",
    "            print(f'=========={self.cityname}==========')\n",
    "            print(f'預測房價落在實際房價+-10%內的機率為:{round(data1[\"y10\"].mean(),4)*100}%')\n",
    "            print(f'預測房價落在實際房價+-20%內的機率為:{round(data1[\"y20\"].mean(),4)*100}%')\n",
    "            print(f'預測房價落在實際房價+-30%內的機率為:{round(data1[\"y30\"].mean(),4)*100}%')\n",
    "            print(\"Model Percentage Error: {:.2f}%\".format(percentage_error))\n",
    "\n",
    "            \n",
    "            print(f\"mean_absolute_error: {mean_absolute_error(y_test, result)}\")\n",
    "            print(f\"mean_squared_error: {mean_squared_error(y_test, result)}\")\n",
    "            print(f\"explained_variance_score: {explained_variance_score(y_test, result)}\")\n",
    "            print(f\"r2_score: {r2_score(y_test, result)}\")\n",
    "\n",
    "        else:\n",
    "            print('模型尚未訓練，請先訓練模型')\n",
    "\n",
    "    \n",
    "    def predictPrice(self, lst):\n",
    "        if os.path.isfile(self.modelpath):\n",
    "            test_data = pd.read_csv(f'./{self.cityname}/test_data.csv')\n",
    "            test_data.drop(['Unnamed: 0', 'y'],axis=1,inplace=True)\n",
    "            predict_data = pd.DataFrame(np.array(lst)).T\n",
    "            predict_data.columns = test_data.columns\n",
    "            # print(predict_data)\n",
    "            \n",
    "            mean = self.mean.drop(['y'])\n",
    "            std = self.std.drop(['y'])\n",
    "            predict_data = np.array((predict_data - mean) / std)\n",
    "            # print(predict_data)\n",
    "\n",
    "            model_mlp = joblib.load(f'./{self.cityname}/model_mlp_aws.pkl')\n",
    "            result = model_mlp.predict(predict_data)\n",
    "            print(result)\n",
    "            result = result * self.std['y'] + self.mean['y']\n",
    "            return predict_data, result\n",
    "        else:\n",
    "            print('模型尚未訓練，請先訓練模型')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aws_profile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mboto3\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m session \u001b[39m=\u001b[39m boto3\u001b[39m.\u001b[39mSession(profile_name\u001b[39m=\u001b[39maws_profile)\n\u001b[0;32m      6\u001b[0m data \u001b[39m=\u001b[39m wr\u001b[39m.\u001b[39ms3\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms3://house-good-job/clean_data/TPE_model_features_clean.csv\u001b[39m\u001b[39m'\u001b[39m, boto3_session\u001b[39m=\u001b[39msession)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(data))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aws_profile' is not defined"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "session = boto3.Session(profile_name=aws_profile)\n",
    "data = wr.s3.read_csv(f's3://house-good-job/clean_data/TPE_model_features_clean.csv', boto3_session=session)\n",
    "print(type(data))\n",
    "\n",
    "data1 = pd.read_csv(f\"./TPE/TPE_model_features_clean.csv\")\n",
    "print(type(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.17386338\n",
      "Iteration 2, loss = 0.10823654\n",
      "Iteration 3, loss = 0.09667964\n",
      "Iteration 4, loss = 0.09035189\n",
      "Iteration 5, loss = 0.08621533\n",
      "Iteration 6, loss = 0.08304415\n",
      "Iteration 7, loss = 0.08062693\n",
      "Iteration 8, loss = 0.07892437\n",
      "Iteration 9, loss = 0.07736565\n",
      "Iteration 10, loss = 0.07608540\n",
      "Iteration 11, loss = 0.07490757\n",
      "Iteration 12, loss = 0.07414381\n",
      "Iteration 13, loss = 0.07311098\n",
      "Iteration 14, loss = 0.07230589\n",
      "Iteration 15, loss = 0.07159850\n",
      "Iteration 16, loss = 0.07103474\n",
      "Iteration 17, loss = 0.07066855\n",
      "Iteration 18, loss = 0.07008490\n",
      "Iteration 19, loss = 0.06947589\n",
      "Iteration 20, loss = 0.06871828\n",
      "Iteration 21, loss = 0.06837818\n",
      "Iteration 22, loss = 0.06818227\n",
      "Iteration 23, loss = 0.06752031\n",
      "Iteration 24, loss = 0.06706190\n",
      "Iteration 25, loss = 0.06712825\n",
      "Iteration 26, loss = 0.06624169\n",
      "Iteration 27, loss = 0.06601182\n",
      "Iteration 28, loss = 0.06575563\n",
      "Iteration 29, loss = 0.06547660\n",
      "Iteration 30, loss = 0.06512982\n",
      "Iteration 31, loss = 0.06460045\n",
      "Iteration 32, loss = 0.06412248\n",
      "Iteration 33, loss = 0.06387387\n",
      "Iteration 34, loss = 0.06372717\n",
      "Iteration 35, loss = 0.06311927\n",
      "Iteration 36, loss = 0.06283603\n",
      "Iteration 37, loss = 0.06281667\n",
      "Iteration 38, loss = 0.06267549\n",
      "Iteration 39, loss = 0.06234071\n",
      "Iteration 40, loss = 0.06203690\n",
      "Iteration 41, loss = 0.06181523\n",
      "Iteration 42, loss = 0.06172051\n",
      "Iteration 43, loss = 0.06170251\n",
      "Iteration 44, loss = 0.06140869\n",
      "Iteration 45, loss = 0.06120195\n",
      "Iteration 46, loss = 0.06111980\n",
      "Iteration 47, loss = 0.06092383\n",
      "Iteration 48, loss = 0.06069904\n",
      "Iteration 49, loss = 0.06080811\n",
      "Iteration 50, loss = 0.06048305\n",
      "Iteration 51, loss = 0.06038385\n",
      "Iteration 52, loss = 0.06022391\n",
      "Iteration 53, loss = 0.06031482\n",
      "Iteration 54, loss = 0.06012599\n",
      "Iteration 55, loss = 0.06011512\n",
      "Iteration 56, loss = 0.06001354\n",
      "Iteration 57, loss = 0.05973582\n",
      "Iteration 58, loss = 0.05953015\n",
      "Iteration 59, loss = 0.05935883\n",
      "Iteration 60, loss = 0.05941427\n",
      "Iteration 61, loss = 0.05926491\n",
      "Iteration 62, loss = 0.05925039\n",
      "Iteration 63, loss = 0.05923623\n",
      "Iteration 64, loss = 0.05910393\n",
      "Iteration 65, loss = 0.05913586\n",
      "Iteration 66, loss = 0.05897648\n",
      "Iteration 67, loss = 0.05883328\n",
      "Iteration 68, loss = 0.05876327\n",
      "Iteration 69, loss = 0.05862558\n",
      "Iteration 70, loss = 0.05851064\n",
      "Iteration 71, loss = 0.05858966\n",
      "Iteration 72, loss = 0.05849224\n",
      "Iteration 73, loss = 0.05844447\n",
      "Iteration 74, loss = 0.05843357\n",
      "Iteration 75, loss = 0.05828945\n",
      "Iteration 76, loss = 0.05792331\n",
      "Iteration 77, loss = 0.05795731\n",
      "Iteration 78, loss = 0.05789770\n",
      "Iteration 79, loss = 0.05807183\n",
      "Iteration 80, loss = 0.05772992\n",
      "Iteration 81, loss = 0.05779496\n",
      "Iteration 82, loss = 0.05778834\n",
      "Iteration 83, loss = 0.05761210\n",
      "Iteration 84, loss = 0.05753990\n",
      "Iteration 85, loss = 0.05762928\n",
      "Iteration 86, loss = 0.05739142\n",
      "Iteration 87, loss = 0.05737310\n",
      "Iteration 88, loss = 0.05734156\n",
      "Iteration 89, loss = 0.05727229\n",
      "Iteration 90, loss = 0.05722987\n",
      "Iteration 91, loss = 0.05721658\n",
      "Iteration 92, loss = 0.05692369\n",
      "Iteration 93, loss = 0.05713114\n",
      "Iteration 94, loss = 0.05697850\n",
      "Iteration 95, loss = 0.05694437\n",
      "Iteration 96, loss = 0.05710686\n",
      "Iteration 97, loss = 0.05680389\n",
      "Iteration 98, loss = 0.05684017\n",
      "Iteration 99, loss = 0.05670680\n",
      "Iteration 100, loss = 0.05674865\n",
      "Iteration 101, loss = 0.05677184\n",
      "Iteration 102, loss = 0.05662629\n",
      "Iteration 103, loss = 0.05650982\n",
      "Iteration 104, loss = 0.05663405\n",
      "Iteration 105, loss = 0.05659498\n",
      "Iteration 106, loss = 0.05635208\n",
      "Iteration 107, loss = 0.05634959\n",
      "Iteration 108, loss = 0.05636160\n",
      "Iteration 109, loss = 0.05643764\n",
      "Iteration 110, loss = 0.05610675\n",
      "Iteration 111, loss = 0.05620470\n",
      "Iteration 112, loss = 0.05614054\n",
      "Iteration 113, loss = 0.05618303\n",
      "Iteration 114, loss = 0.05627006\n",
      "Iteration 115, loss = 0.05611231\n",
      "Iteration 116, loss = 0.05608752\n",
      "Iteration 117, loss = 0.05612167\n",
      "Iteration 118, loss = 0.05608022\n",
      "Iteration 119, loss = 0.05608711\n",
      "Iteration 120, loss = 0.05583990\n",
      "Iteration 121, loss = 0.05597702\n",
      "Iteration 122, loss = 0.05569138\n",
      "Iteration 123, loss = 0.05578908\n",
      "Iteration 124, loss = 0.05588630\n",
      "Iteration 125, loss = 0.05589006\n",
      "Iteration 126, loss = 0.05553527\n",
      "Iteration 127, loss = 0.05567213\n",
      "Iteration 128, loss = 0.05570125\n",
      "Iteration 129, loss = 0.05553972\n",
      "Iteration 130, loss = 0.05558781\n",
      "Iteration 131, loss = 0.05548662\n",
      "Iteration 132, loss = 0.05565256\n",
      "Iteration 133, loss = 0.05544361\n",
      "Iteration 134, loss = 0.05543803\n",
      "Iteration 135, loss = 0.05545535\n",
      "Iteration 136, loss = 0.05523907\n",
      "Iteration 137, loss = 0.05536540\n",
      "Iteration 138, loss = 0.05543486\n",
      "Iteration 139, loss = 0.05519864\n",
      "Iteration 140, loss = 0.05525623\n",
      "Iteration 141, loss = 0.05506834\n",
      "Iteration 142, loss = 0.05516691\n",
      "Iteration 143, loss = 0.05525862\n",
      "Iteration 144, loss = 0.05504351\n",
      "Iteration 145, loss = 0.05523396\n",
      "Iteration 146, loss = 0.05508728\n",
      "Iteration 147, loss = 0.05512366\n",
      "Iteration 148, loss = 0.05501263\n",
      "Iteration 149, loss = 0.05509652\n",
      "Iteration 150, loss = 0.05490476\n",
      "Iteration 151, loss = 0.05507560\n",
      "Iteration 152, loss = 0.05504428\n",
      "Iteration 153, loss = 0.05482044\n",
      "Iteration 154, loss = 0.05500076\n",
      "Iteration 155, loss = 0.05517459\n",
      "Iteration 156, loss = 0.05472816\n",
      "Iteration 157, loss = 0.05487089\n",
      "Iteration 158, loss = 0.05480245\n",
      "Iteration 159, loss = 0.05456983\n",
      "Iteration 160, loss = 0.05478606\n",
      "Iteration 161, loss = 0.05468030\n",
      "Iteration 162, loss = 0.05459691\n",
      "Iteration 163, loss = 0.05468151\n",
      "Iteration 164, loss = 0.05475742\n",
      "Iteration 165, loss = 0.05464977\n",
      "Iteration 166, loss = 0.05457750\n",
      "Iteration 167, loss = 0.05469222\n",
      "Iteration 168, loss = 0.05446475\n",
      "Iteration 169, loss = 0.05442719\n",
      "Iteration 170, loss = 0.05443536\n",
      "Iteration 171, loss = 0.05452863\n",
      "Iteration 172, loss = 0.05447264\n",
      "Iteration 173, loss = 0.05433307\n",
      "Iteration 174, loss = 0.05442378\n",
      "Iteration 175, loss = 0.05432185\n",
      "Iteration 176, loss = 0.05437698\n",
      "Iteration 177, loss = 0.05427491\n",
      "Iteration 178, loss = 0.05439104\n",
      "Iteration 179, loss = 0.05421065\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "model score: 0.8944089881281152\n"
     ]
    }
   ],
   "source": [
    "object=HousePriceModel_aws('TPE')\n",
    "object.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.24558874\n",
      "Iteration 2, loss = 0.14658499\n",
      "Iteration 3, loss = 0.12760973\n",
      "Iteration 4, loss = 0.11830921\n",
      "Iteration 5, loss = 0.11195783\n",
      "Iteration 6, loss = 0.10798348\n",
      "Iteration 7, loss = 0.10472928\n",
      "Iteration 8, loss = 0.10142735\n",
      "Iteration 9, loss = 0.09894034\n",
      "Iteration 10, loss = 0.09685403\n",
      "Iteration 11, loss = 0.09558511\n",
      "Iteration 12, loss = 0.09409064\n",
      "Iteration 13, loss = 0.09323292\n",
      "Iteration 14, loss = 0.09182332\n",
      "Iteration 15, loss = 0.09115374\n",
      "Iteration 16, loss = 0.08941093\n",
      "Iteration 17, loss = 0.08769877\n",
      "Iteration 18, loss = 0.08727735\n",
      "Iteration 19, loss = 0.08658971\n",
      "Iteration 20, loss = 0.08635791\n",
      "Iteration 21, loss = 0.08508478\n",
      "Iteration 22, loss = 0.08430353\n",
      "Iteration 23, loss = 0.08357082\n",
      "Iteration 24, loss = 0.08366279\n",
      "Iteration 25, loss = 0.08181599\n",
      "Iteration 26, loss = 0.08135391\n",
      "Iteration 27, loss = 0.08137055\n",
      "Iteration 28, loss = 0.08084694\n",
      "Iteration 29, loss = 0.08022249\n",
      "Iteration 30, loss = 0.07925328\n",
      "Iteration 31, loss = 0.07897214\n",
      "Iteration 32, loss = 0.07904141\n",
      "Iteration 33, loss = 0.07858947\n",
      "Iteration 34, loss = 0.07827448\n",
      "Iteration 35, loss = 0.07718769\n",
      "Iteration 36, loss = 0.07704579\n",
      "Iteration 37, loss = 0.07706881\n",
      "Iteration 38, loss = 0.07691534\n",
      "Iteration 39, loss = 0.07601437\n",
      "Iteration 40, loss = 0.07575760\n",
      "Iteration 41, loss = 0.07460289\n",
      "Iteration 42, loss = 0.07558538\n",
      "Iteration 43, loss = 0.07493065\n",
      "Iteration 44, loss = 0.07535309\n",
      "Iteration 45, loss = 0.07452546\n",
      "Iteration 46, loss = 0.07428451\n",
      "Iteration 47, loss = 0.07354435\n",
      "Iteration 48, loss = 0.07345036\n",
      "Iteration 49, loss = 0.07419947\n",
      "Iteration 50, loss = 0.07371317\n",
      "Iteration 51, loss = 0.07274095\n",
      "Iteration 52, loss = 0.07311980\n",
      "Iteration 53, loss = 0.07267152\n",
      "Iteration 54, loss = 0.07203096\n",
      "Iteration 55, loss = 0.07205949\n",
      "Iteration 56, loss = 0.07136731\n",
      "Iteration 57, loss = 0.07163705\n",
      "Iteration 58, loss = 0.07190780\n",
      "Iteration 59, loss = 0.07146265\n",
      "Iteration 60, loss = 0.07078960\n",
      "Iteration 61, loss = 0.07127302\n",
      "Iteration 62, loss = 0.07070749\n",
      "Iteration 63, loss = 0.07100225\n",
      "Iteration 64, loss = 0.07071420\n",
      "Iteration 65, loss = 0.07071879\n",
      "Iteration 66, loss = 0.07015012\n",
      "Iteration 67, loss = 0.06991396\n",
      "Iteration 68, loss = 0.06921529\n",
      "Iteration 69, loss = 0.06991664\n",
      "Iteration 70, loss = 0.07014550\n",
      "Iteration 71, loss = 0.06901553\n",
      "Iteration 72, loss = 0.06893632\n",
      "Iteration 73, loss = 0.06891038\n",
      "Iteration 74, loss = 0.06865586\n",
      "Iteration 75, loss = 0.06897265\n",
      "Iteration 76, loss = 0.06871220\n",
      "Iteration 77, loss = 0.06821938\n",
      "Iteration 78, loss = 0.06832431\n",
      "Iteration 79, loss = 0.06867735\n",
      "Iteration 80, loss = 0.06762821\n",
      "Iteration 81, loss = 0.06804294\n",
      "Iteration 82, loss = 0.06758722\n",
      "Iteration 83, loss = 0.06789274\n",
      "Iteration 84, loss = 0.06740449\n",
      "Iteration 85, loss = 0.06786515\n",
      "Iteration 86, loss = 0.06742046\n",
      "Iteration 87, loss = 0.06716281\n",
      "Iteration 88, loss = 0.06713354\n",
      "Iteration 89, loss = 0.06687574\n",
      "Iteration 90, loss = 0.06720653\n",
      "Iteration 91, loss = 0.06655820\n",
      "Iteration 92, loss = 0.06723158\n",
      "Iteration 93, loss = 0.06680966\n",
      "Iteration 94, loss = 0.06636056\n",
      "Iteration 95, loss = 0.06667201\n",
      "Iteration 96, loss = 0.06677946\n",
      "Iteration 97, loss = 0.06625503\n",
      "Iteration 98, loss = 0.06633671\n",
      "Iteration 99, loss = 0.06609145\n",
      "Iteration 100, loss = 0.06531172\n",
      "Iteration 101, loss = 0.06628051\n",
      "Iteration 102, loss = 0.06546527\n",
      "Iteration 103, loss = 0.06560435\n",
      "Iteration 104, loss = 0.06573775\n",
      "Iteration 105, loss = 0.06540634\n",
      "Iteration 106, loss = 0.06490929\n",
      "Iteration 107, loss = 0.06488507\n",
      "Iteration 108, loss = 0.06508754\n",
      "Iteration 109, loss = 0.06536345\n",
      "Iteration 110, loss = 0.06501016\n",
      "Iteration 111, loss = 0.06498123\n",
      "Iteration 112, loss = 0.06468485\n",
      "Iteration 113, loss = 0.06460796\n",
      "Iteration 114, loss = 0.06410022\n",
      "Iteration 115, loss = 0.06558053\n",
      "Iteration 116, loss = 0.06417667\n",
      "Iteration 117, loss = 0.06424347\n",
      "Iteration 118, loss = 0.06449889\n",
      "Iteration 119, loss = 0.06461826\n",
      "Iteration 120, loss = 0.06397519\n",
      "Iteration 121, loss = 0.06410574\n",
      "Iteration 122, loss = 0.06395549\n",
      "Iteration 123, loss = 0.06368068\n",
      "Iteration 124, loss = 0.06351539\n",
      "Iteration 125, loss = 0.06407219\n",
      "Iteration 126, loss = 0.06357376\n",
      "Iteration 127, loss = 0.06327848\n",
      "Iteration 128, loss = 0.06365375\n",
      "Iteration 129, loss = 0.06351679\n",
      "Iteration 130, loss = 0.06329060\n",
      "Iteration 131, loss = 0.06344990\n",
      "Iteration 132, loss = 0.06389215\n",
      "Iteration 133, loss = 0.06329171\n",
      "Iteration 134, loss = 0.06296948\n",
      "Iteration 135, loss = 0.06302939\n",
      "Iteration 136, loss = 0.06292349\n",
      "Iteration 137, loss = 0.06302336\n",
      "Iteration 138, loss = 0.06323632\n",
      "Iteration 139, loss = 0.06261445\n",
      "Iteration 140, loss = 0.06277616\n",
      "Iteration 141, loss = 0.06264668\n",
      "Iteration 142, loss = 0.06260057\n",
      "Iteration 143, loss = 0.06257486\n",
      "Iteration 144, loss = 0.06228621\n",
      "Iteration 145, loss = 0.06277266\n",
      "Iteration 146, loss = 0.06245920\n",
      "Iteration 147, loss = 0.06189541\n",
      "Iteration 148, loss = 0.06208904\n",
      "Iteration 149, loss = 0.06233206\n",
      "Iteration 150, loss = 0.06219903\n",
      "Iteration 151, loss = 0.06255597\n",
      "Iteration 152, loss = 0.06196146\n",
      "Iteration 153, loss = 0.06189837\n",
      "Iteration 154, loss = 0.06160256\n",
      "Iteration 155, loss = 0.06122406\n",
      "Iteration 156, loss = 0.06122100\n",
      "Iteration 157, loss = 0.06128336\n",
      "Iteration 158, loss = 0.06135300\n",
      "Iteration 159, loss = 0.06122644\n",
      "Iteration 160, loss = 0.06161675\n",
      "Iteration 161, loss = 0.06100931\n",
      "Iteration 162, loss = 0.06168834\n",
      "Iteration 163, loss = 0.06124256\n",
      "Iteration 164, loss = 0.06102790\n",
      "Iteration 165, loss = 0.06091617\n",
      "Iteration 166, loss = 0.06093637\n",
      "Iteration 167, loss = 0.06123792\n",
      "Iteration 168, loss = 0.06117138\n",
      "Iteration 169, loss = 0.06034206\n",
      "Iteration 170, loss = 0.06098952\n",
      "Iteration 171, loss = 0.06087502\n",
      "Iteration 172, loss = 0.06041717\n",
      "Iteration 173, loss = 0.06068669\n",
      "Iteration 174, loss = 0.06036783\n",
      "Iteration 175, loss = 0.06035968\n",
      "Iteration 176, loss = 0.06037271\n",
      "Iteration 177, loss = 0.06087087\n",
      "Iteration 178, loss = 0.06024799\n",
      "Iteration 179, loss = 0.06043186\n",
      "Iteration 180, loss = 0.05991848\n",
      "Iteration 181, loss = 0.06003834\n",
      "Iteration 182, loss = 0.05991229\n",
      "Iteration 183, loss = 0.06028045\n",
      "Iteration 184, loss = 0.05986473\n",
      "Iteration 185, loss = 0.06018283\n",
      "Iteration 186, loss = 0.06026825\n",
      "Iteration 187, loss = 0.05945499\n",
      "Iteration 188, loss = 0.06013081\n",
      "Iteration 189, loss = 0.06015269\n",
      "Iteration 190, loss = 0.05966720\n",
      "Iteration 191, loss = 0.05948465\n",
      "Iteration 192, loss = 0.05987268\n",
      "Iteration 193, loss = 0.05989066\n",
      "Iteration 194, loss = 0.05952969\n",
      "Iteration 195, loss = 0.05916777\n",
      "Iteration 196, loss = 0.06002559\n",
      "Iteration 197, loss = 0.06057098\n",
      "Iteration 198, loss = 0.05886483\n",
      "Iteration 199, loss = 0.05885361\n",
      "Iteration 200, loss = 0.05896967\n",
      "Iteration 201, loss = 0.05915735\n",
      "Iteration 202, loss = 0.05924717\n",
      "Iteration 203, loss = 0.05897558\n",
      "Iteration 204, loss = 0.05932044\n",
      "Iteration 205, loss = 0.05928405\n",
      "Iteration 206, loss = 0.05903393\n",
      "Iteration 207, loss = 0.05905463\n",
      "Iteration 208, loss = 0.05890460\n",
      "Iteration 209, loss = 0.05844002\n",
      "Iteration 210, loss = 0.05847057\n",
      "Iteration 211, loss = 0.05895009\n",
      "Iteration 212, loss = 0.05904790\n",
      "Iteration 213, loss = 0.05842640\n",
      "Iteration 214, loss = 0.05864224\n",
      "Iteration 215, loss = 0.05835164\n",
      "Iteration 216, loss = 0.05869958\n",
      "Iteration 217, loss = 0.05843028\n",
      "Iteration 218, loss = 0.05821654\n",
      "Iteration 219, loss = 0.05853832\n",
      "Iteration 220, loss = 0.05920361\n",
      "Iteration 221, loss = 0.05811683\n",
      "Iteration 222, loss = 0.05803819\n",
      "Iteration 223, loss = 0.05836730\n",
      "Iteration 224, loss = 0.05780682\n",
      "Iteration 225, loss = 0.05805535\n",
      "Iteration 226, loss = 0.05826855\n",
      "Iteration 227, loss = 0.05833433\n",
      "Iteration 228, loss = 0.05839111\n",
      "Iteration 229, loss = 0.05769072\n",
      "Iteration 230, loss = 0.05776972\n",
      "Iteration 231, loss = 0.05790240\n",
      "Iteration 232, loss = 0.05750697\n",
      "Iteration 233, loss = 0.05817915\n",
      "Iteration 234, loss = 0.05754354\n",
      "Iteration 235, loss = 0.05775337\n",
      "Iteration 236, loss = 0.05730459\n",
      "Iteration 237, loss = 0.05779943\n",
      "Iteration 238, loss = 0.05750264\n",
      "Iteration 239, loss = 0.05773083\n",
      "Iteration 240, loss = 0.05792521\n",
      "Iteration 241, loss = 0.05742325\n",
      "Iteration 242, loss = 0.05822382\n",
      "Iteration 243, loss = 0.05753986\n",
      "Iteration 244, loss = 0.05704903\n",
      "Iteration 245, loss = 0.05785029\n",
      "Iteration 246, loss = 0.05732868\n",
      "Iteration 247, loss = 0.05682581\n",
      "Iteration 248, loss = 0.05731978\n",
      "Iteration 249, loss = 0.05723317\n",
      "Iteration 250, loss = 0.05749163\n",
      "Iteration 251, loss = 0.05706378\n",
      "Iteration 252, loss = 0.05716416\n",
      "Iteration 253, loss = 0.05704220\n",
      "Iteration 254, loss = 0.05708894\n",
      "Iteration 255, loss = 0.05687830\n",
      "Iteration 256, loss = 0.05757570\n",
      "Iteration 257, loss = 0.05703225\n",
      "Iteration 258, loss = 0.05673600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "model score: 0.891798155263546\n"
     ]
    }
   ],
   "source": [
    "object=HousePriceModel_aws('KEL')\n",
    "object.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.09884922\n",
      "Iteration 2, loss = 0.07771801\n",
      "Iteration 3, loss = 0.09220399\n",
      "Iteration 4, loss = 0.06206811\n",
      "Iteration 5, loss = 0.05982684\n",
      "Iteration 6, loss = 0.05968323\n",
      "Iteration 7, loss = 0.06188078\n",
      "Iteration 8, loss = 0.05948468\n",
      "Iteration 9, loss = 0.05939872\n",
      "Iteration 10, loss = 0.05611902\n",
      "Iteration 11, loss = 0.05491857\n",
      "Iteration 12, loss = 0.05428133\n",
      "Iteration 13, loss = 0.05405875\n",
      "Iteration 14, loss = 0.05351697\n",
      "Iteration 15, loss = 0.05216813\n",
      "Iteration 16, loss = 0.05086524\n",
      "Iteration 17, loss = 0.04977911\n",
      "Iteration 18, loss = 0.04902902\n",
      "Iteration 19, loss = 0.04806497\n",
      "Iteration 20, loss = 0.04769516\n",
      "Iteration 21, loss = 0.04736449\n",
      "Iteration 22, loss = 0.04705446\n",
      "Iteration 23, loss = 0.04699376\n",
      "Iteration 24, loss = 0.04655509\n",
      "Iteration 25, loss = 0.04618543\n",
      "Iteration 26, loss = 0.04583142\n",
      "Iteration 27, loss = 0.04575897\n",
      "Iteration 28, loss = 0.04558076\n",
      "Iteration 29, loss = 0.04549026\n",
      "Iteration 30, loss = 0.04540446\n",
      "Iteration 31, loss = 0.04511380\n",
      "Iteration 32, loss = 0.04507281\n",
      "Iteration 33, loss = 0.04488640\n",
      "Iteration 34, loss = 0.04471690\n",
      "Iteration 35, loss = 0.04576436\n",
      "Iteration 36, loss = 0.04459712\n",
      "Iteration 37, loss = 0.04428685\n",
      "Iteration 38, loss = 0.04422856\n",
      "Iteration 39, loss = 0.04414447\n",
      "Iteration 40, loss = 0.04405652\n",
      "Iteration 41, loss = 0.04400496\n",
      "Iteration 42, loss = 0.04390626\n",
      "Iteration 43, loss = 0.04368061\n",
      "Iteration 44, loss = 0.04373252\n",
      "Iteration 45, loss = 0.04362775\n",
      "Iteration 46, loss = 0.04367749\n",
      "Iteration 47, loss = 0.04360543\n",
      "Iteration 48, loss = 0.04341646\n",
      "Iteration 49, loss = 0.04357601\n",
      "Iteration 50, loss = 0.04342098\n",
      "Iteration 51, loss = 0.04321593\n",
      "Iteration 52, loss = 0.04314667\n",
      "Iteration 53, loss = 0.04317766\n",
      "Iteration 54, loss = 0.04318470\n",
      "Iteration 55, loss = 0.04305977\n",
      "Iteration 56, loss = 0.04370646\n",
      "Iteration 57, loss = 0.04337846\n",
      "Iteration 58, loss = 0.04303512\n",
      "Iteration 59, loss = 0.04297195\n",
      "Iteration 60, loss = 0.04315497\n",
      "Iteration 61, loss = 0.04266362\n",
      "Iteration 62, loss = 0.04274582\n",
      "Iteration 63, loss = 0.04263975\n",
      "Iteration 64, loss = 0.04261008\n",
      "Iteration 65, loss = 0.04248732\n",
      "Iteration 66, loss = 0.04266786\n",
      "Iteration 67, loss = 0.04239966\n",
      "Iteration 68, loss = 0.04249837\n",
      "Iteration 69, loss = 0.04246285\n",
      "Iteration 70, loss = 0.04233063\n",
      "Iteration 71, loss = 0.04224510\n",
      "Iteration 72, loss = 0.04215741\n",
      "Iteration 73, loss = 0.04227164\n",
      "Iteration 74, loss = 0.04225393\n",
      "Iteration 75, loss = 0.04223892\n",
      "Iteration 76, loss = 0.04202160\n",
      "Iteration 77, loss = 0.04206333\n",
      "Iteration 78, loss = 0.04206431\n",
      "Iteration 79, loss = 0.04217826\n",
      "Iteration 80, loss = 0.04200147\n",
      "Iteration 81, loss = 0.04181739\n",
      "Iteration 82, loss = 0.04181861\n",
      "Iteration 83, loss = 0.04179770\n",
      "Iteration 84, loss = 0.04181952\n",
      "Iteration 85, loss = 0.04177835\n",
      "Iteration 86, loss = 0.04180221\n",
      "Iteration 87, loss = 0.04182615\n",
      "Iteration 88, loss = 0.04230504\n",
      "Iteration 89, loss = 0.04177529\n",
      "Iteration 90, loss = 0.04153638\n",
      "Iteration 91, loss = 0.04166824\n",
      "Iteration 92, loss = 0.04171833\n",
      "Iteration 93, loss = 0.04164065\n",
      "Iteration 94, loss = 0.04157149\n",
      "Iteration 95, loss = 0.04177461\n",
      "Iteration 96, loss = 0.04148542\n",
      "Iteration 97, loss = 0.04149811\n",
      "Iteration 98, loss = 0.04146324\n",
      "Iteration 99, loss = 0.04141188\n",
      "Iteration 100, loss = 0.04142792\n",
      "Iteration 101, loss = 0.04148783\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "model score: 0.9197078494019124\n"
     ]
    }
   ],
   "source": [
    "object=HousePriceModel_aws('NTPC')\n",
    "object.trainModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
