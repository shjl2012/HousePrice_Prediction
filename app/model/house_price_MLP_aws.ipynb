{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boto3 呼叫 aws bucket\n",
    "\n",
    "參考資料：\n",
    "\n",
    "https://dev.to/gbhorwood/managing-your-aws-resources-with-python-and-boto3-1ceb\n",
    "\n",
    "https://dev.to/aws-builders/how-to-list-contents-of-s3-bucket-using-boto3-python-47mm\n",
    "\n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/guide/session.html\n",
    "\n",
    "https://www.learnaws.org/2022/09/27/pandas-read-s3/\n",
    "\n",
    "https://aws-sdk-pandas.readthedocs.io/en/stable/tutorials/002%20-%20Sessions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "# configuration\n",
    "\n",
    "# --> NEW\n",
    "# the name of the aws profile\n",
    "aws_profile = \"house-good-job_john\"\n",
    "\n",
    "# --> NEW\n",
    "# aws credentials read in from ~/.aws/credentials\n",
    "aws_access_key_id = None\n",
    "aws_secret_access_key = None\n",
    "aws_region = \"ap-northeast-1\"\n",
    "\n",
    "\n",
    "# --> NEW\n",
    "def get_aws_credentials():\n",
    "    \"\"\"\n",
    "    Gets the aws credentials from ~/.aws/credentials\n",
    "    for the aws profile name\n",
    "    \"\"\"\n",
    "    import configparser\n",
    "    import os\n",
    "\n",
    "    # the aws profile we configured\n",
    "    global aws_profile\n",
    "\n",
    "    # the global variables where we store the aws credentials\n",
    "    global aws_access_key_id\n",
    "    global aws_secret_access_key\n",
    "\n",
    "    # parse the aws credentials file\n",
    "    path = os.environ['HOME'] + '/.aws/credentials'\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(path)\n",
    "\n",
    "    # read in the aws_access_key_id and the aws_secret_access_key\n",
    "    # if the profile does not exist, error and exit\n",
    "    if aws_profile in config.sections():\n",
    "        aws_access_key_id = config[aws_profile]['aws_access_key_id']\n",
    "        aws_secret_access_key = config[aws_profile]['aws_secret_access_key']\n",
    "    else:\n",
    "        print(\"Cannot find profile '{}' in {}\".format(aws_profile, path), True)\n",
    "        sys.exit()\n",
    "\n",
    "    # if we don't have both the access and secret key, error and exit\n",
    "    if aws_access_key_id is None or aws_secret_access_key is None:\n",
    "        print(\"AWS config values not set in '{}' in {}\".format(aws_profile, path), True)\n",
    "        sys.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_crentials confirmation\n",
    "\n",
    "# get_aws_credentials()\n",
    "# print(aws_profile)\n",
    "# print(aws_access_key_id)\n",
    "# print(aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_data/\n",
      "clean_data/KEL_model_features_clean.csv\n",
      "clean_data/NTPC_model_features_clean.csv\n",
      "clean_data/TPE_model_features_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name=aws_profile)\n",
    "s3_client = session.client('s3')\n",
    "\n",
    "objects = s3_client.list_objects_v2(Bucket='house-good-job')\n",
    "\n",
    "for obj in objects['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import joblib, os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "\n",
    "class HousePriceModel_aws:\n",
    "\n",
    "    def __init__(self, c):\n",
    "        self.cityname = c\n",
    "        self.modelpath = f'./{self.cityname}/model_mlp_aws.pkl'\n",
    "        aws_profile = \"house-good-job_john\"\n",
    "        session = boto3.Session(profile_name=aws_profile)\n",
    "        data = wr.s3.read_csv(f's3://house-good-job/clean_data/{self.cityname}_model_features_clean.csv', boto3_session=session)\n",
    "        # data=pd.read_csv(f'./{self.cityname}_model_features_clean.csv')\n",
    "        # 單熱編碼\n",
    "        data_class = pd.get_dummies(data['鄉鎮市區'])\n",
    "        data_class.columns = ['鄉鎮市區_' + str(x) for x in data_class.columns]\n",
    "        data = pd.concat([data, data_class], axis = 1)\n",
    "\n",
    "        # 刪除資料分類用欄位\n",
    "        data.insert(data.shape[1], 'y', data['單價元平方公尺'])\n",
    "        data.drop(['單價元平方公尺', 'Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.2', \n",
    "        '鄉鎮市區', 'geometry'],axis=1,inplace=True)\n",
    "\n",
    "        # 低變異過濾\n",
    "        data = data.loc[:, data.std() > 0]\n",
    "        data = data.dropna()\n",
    "        self.feature_count = data.shape[1]\n",
    "\n",
    "        # 訓練集 & 測試集\n",
    "        test_data = data.loc[data['交易年份'] >= 111]\n",
    "        test_data.to_csv(f'./{self.cityname}/test_data.csv')\n",
    "        train_data =  data.loc[data['交易年份'] < 111]\n",
    "        \n",
    "        # 資料標準化\n",
    "        self.mean = train_data.mean()\n",
    "        self.std = train_data.std()\n",
    "        self.train_data = (train_data-self.mean)/self.std\n",
    "\n",
    "        \n",
    "    def trainModel(self):\n",
    "        X_train = np.array(self.train_data.drop('y', axis='columns'))\n",
    "        y_train = np.array(self.train_data['y'])\n",
    "\n",
    "        model_mlp = MLPRegressor(random_state=14,max_iter = 400,activation='relu', hidden_layer_sizes=(int(self.feature_count*1/2),int(self.feature_count*1/4)))\n",
    "        model_mlp.fit(X_train, y_train)\n",
    "        mlp_score=model_mlp.score(X_train,y_train)\n",
    "\n",
    "        joblib.dump(model_mlp, f'./{self.cityname}/model_mlp_aws.pkl')\n",
    "        print(f'model score: {mlp_score}')\n",
    "\n",
    "    def testModel(self, testfile):\n",
    "        if os.path.isfile(self.modelpath):\n",
    "            test_data = pd.read_csv(f'./{self.cityname}/{testfile}.csv')\n",
    "            test_data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "            \n",
    "            test_data = (test_data - self.mean) / self.std\n",
    "            X_test = np.array(test_data.drop('y', axis='columns'))\n",
    "            y_test = np.array(test_data['y'])\n",
    "\n",
    "            \n",
    "            model_mlp = joblib.load(f'./{self.cityname}/model_mlp_aws.pkl')\n",
    "            result = model_mlp.predict(X_test)\n",
    "            fig = plt.figure(figsize=(10,5))\n",
    "            residuals = (y_test * self.std['y'] + self.mean['y'])- (result * self.std['y'] + self.mean['y'])\n",
    "            pd.DataFrame(residuals).to_csv(f'./{self.cityname}/residuals.csv')\n",
    "\n",
    "            data1 = pd.DataFrame({'origin':y_test * self.std['y'] + self.mean['y'],'predict':result* self.std['y'] + self.mean['y'],\n",
    "                                'residual':(y_test * self.std['y'] + self.mean['y']) - (result* self.std['y'] + self.mean['y'])})\n",
    "            percentage_error = np.mean(np.abs(data1['origin'] - data1['predict'])) / np.mean(data1['origin']) * 100\n",
    "            data1['residual_abs'] = data1['residual'].abs()\n",
    "            data1['y10'] = data1['origin'] / 10 - data1['residual_abs']\n",
    "            data1['y20'] = data1['origin'] / 5 - data1['residual_abs']\n",
    "            data1['y30'] = data1['origin'] / 3.333 - data1['residual_abs']\n",
    "            data1.loc[data1['y10'] >= 0, 'y10'] = 1\n",
    "            data1.loc[data1['y10'] < 0 , 'y10'] = 0\n",
    "            data1.loc[data1['y20'] >= 0, 'y20'] = 1\n",
    "            data1.loc[data1['y20'] < 0 , 'y20'] = 0\n",
    "            data1.loc[data1['y30'] >= 0, 'y30'] = 1\n",
    "            data1.loc[data1['y30'] < 0 , 'y30'] = 0\n",
    "            \n",
    "\n",
    "            print(f'=========={self.cityname}==========')\n",
    "            print(f'預測房價落在實際房價+-10%內的機率為:{round(data1[\"y10\"].mean(),4)*100}%')\n",
    "            print(f'預測房價落在實際房價+-20%內的機率為:{round(data1[\"y20\"].mean(),4)*100}%')\n",
    "            print(f'預測房價落在實際房價+-30%內的機率為:{round(data1[\"y30\"].mean(),4)*100}%')\n",
    "            print(\"Model Percentage Error: {:.2f}%\".format(percentage_error))\n",
    "\n",
    "            \n",
    "            print(f\"mean_absolute_error: {mean_absolute_error(y_test, result)}\")\n",
    "            print(f\"mean_squared_error: {mean_squared_error(y_test, result)}\")\n",
    "            print(f\"explained_variance_score: {explained_variance_score(y_test, result)}\")\n",
    "            print(f\"r2_score: {r2_score(y_test, result)}\")\n",
    "\n",
    "        else:\n",
    "            print('模型尚未訓練，請先訓練模型')\n",
    "\n",
    "    \n",
    "    def predictPrice(self, lst):\n",
    "        if os.path.isfile(self.modelpath):\n",
    "            test_data = pd.read_csv(f'./{self.cityname}/test_data.csv')\n",
    "            test_data.drop(['Unnamed: 0', 'y'],axis=1,inplace=True)\n",
    "            predict_data = pd.DataFrame(np.array(lst)).T\n",
    "            predict_data.columns = test_data.columns\n",
    "            # print(predict_data)\n",
    "            \n",
    "            mean = self.mean.drop(['y'])\n",
    "            std = self.std.drop(['y'])\n",
    "            predict_data = np.array((predict_data - mean) / std)\n",
    "            # print(predict_data)\n",
    "\n",
    "            model_mlp = joblib.load(f'./{self.cityname}/model_mlp_aws.pkl')\n",
    "            result = model_mlp.predict(predict_data)\n",
    "            print(result)\n",
    "            result = result * self.std['y'] + self.mean['y']\n",
    "            return predict_data, result\n",
    "        else:\n",
    "            print('模型尚未訓練，請先訓練模型')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "session = boto3.Session(profile_name=aws_profile)\n",
    "data = wr.s3.read_csv(f's3://house-good-job/clean_data/TPE_model_features_clean.csv', boto3_session=session)\n",
    "print(type(data))\n",
    "\n",
    "data1 = pd.read_csv(f\"./TPE_model_features_clean.csv\")\n",
    "print(type(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.8768887163456685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnlin/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "object=HousePriceModel_aws('TPE')\n",
    "object.trainModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
